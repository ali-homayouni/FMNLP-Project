{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sC7vclyLA2F"
      },
      "source": [
        "# Initializing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-dvDjY8LRAF"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Javascript\n",
        "def resize_colab_cell():\n",
        "  display(Javascript('google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'))\n",
        "get_ipython().events.register('pre_run_cell', resize_colab_cell)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AB1sHwEU9Oe",
        "outputId": "8b1b4ffe-2203-45f9-854c-28f6bc259afb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hazm in /usr/local/lib/python3.8/dist-packages (0.7.0)\n",
            "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from hazm) (0.2.1)\n",
            "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.8/dist-packages (from hazm) (3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.8/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install transformers\n",
        "!pip install -U -q PyDrive\n",
        "!pip install hazm\n",
        "!pip install sentencepiece\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edOh9ooiIW1B",
        "outputId": "fbd0b20c-e3bb-4628-a696-7f25d377873d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found device: Tesla T4, n_gpu: 1\n",
            "1.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "assert torch.cuda.is_available()\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import random\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig, RobertaForSequenceClassification\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import BertTokenizer, XLMRobertaTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel\n",
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import sys\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from hazm import word_tokenize\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = torch.cuda.get_device_name()\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n",
        "device = torch.device(\"cuda\")\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1"
      ],
      "metadata": {
        "id": "5sa7-V5Ncplw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyuCu2y9lmBM"
      },
      "source": [
        "## Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import emoji\n",
        "import re\n",
        "\n",
        "not_punctuation = '[^ضصثقفغعهخحجچپشسیبلاتنمکگظطزرذدئوۀآةيژؤإأء]+'\n",
        "\n",
        "def emoji2word(tw):\n",
        "    return emoji.demojize(tw)\n",
        "\n",
        "def remove_links(tw):\n",
        "    return re.sub(r'^https?:\\/\\/.*[\\r\\n]*', 'http', tw, flags=re.MULTILINE)\n",
        "\n",
        "def remove_eng(tw):\n",
        "    return re.sub('[a-zA-Z]','',tw)\n",
        "\n",
        "def keep_fa(tw):\n",
        "  return re.sub(not_punctuation, \" \", tw)\n",
        "\n",
        "def text_cleaner(tw):\n",
        "  try:\n",
        "    data = remove_links(str(tw))\n",
        "    data = emoji2word(data)\n",
        "    data = keep_fa(data)\n",
        "    return data\n",
        "  except:\n",
        "    print('errrrrr',tw)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5ae7TlvUDtAr",
        "outputId": "274ce5ac-ecf4-4437-d00e-9437453dfedc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3gh6oaovk0V3",
        "outputId": "428ef6a3-05f8-41a4-8008-634f6106eb37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/tweetAll20.xlsx')\n",
        "# df = df.loc[df['judged'] == 1]\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df['label'] = df['label'].apply(lambda x: str(x).strip())\n",
        "df['tweet'] = df['tweet'].apply(lambda x: str(x))\n",
        "# df['tweet'] = df['tweet'].apply(lambda x: text_cleaner(x))\n",
        "# df = df.head(2000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].apply(lambda x: 0 if x == '0- NO' else 1 if x == '1- Offensive' else 2)\n",
        "df0 = df.loc[df['label'] == 0]#.sample(n = 3025)\n",
        "df1 = df.loc[df['label'] == 1]#.sample(n = 3025)\n",
        "df2 = df.loc[df['label'] == 2]\n",
        "df = pd.concat([df0,df1,df2]).reset_index(drop=True)\n",
        "df.groupby(['label'])['label'].count().reset_index(name='counts')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "rXX98FCGsi-3",
        "outputId": "afff7079-4d93-4c97-e2fb-957a5885ca2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  counts\n",
              "0      0   38630\n",
              "1      1   16349\n",
              "2      2    3025"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1c6dafb-14b5-4841-b8b9-d0625ae79135\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>38630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>16349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1c6dafb-14b5-4841-b8b9-d0625ae79135')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1c6dafb-14b5-4841-b8b9-d0625ae79135 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1c6dafb-14b5-4841-b8b9-d0625ae79135');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "id": "Zh2gD8Acw89s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2ed07ed3-9b5a-4d63-cc3f-36ee35e2d31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T8hFjCA7mJY_",
        "outputId": "eb557e25-440b-40eb-b65a-5de61e531ce5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "df['tweet_tkn'] = df['tweet'].apply(lambda x: word_tokenize(x))\n",
        "df['tweet_tkn_len'] = df['tweet_tkn'].apply(lambda x: len(x))\n",
        "df['status'] = 'train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YB2TXfW1ZKYg",
        "outputId": "8edcff53-bc69-417e-9163-d9d3d11dc62a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "numbers = df.loc[df['judged'] == 1].groupby(['label'])['label'].count().reset_index(name='counts')\n",
        "for i, row in numbers.iterrows():\n",
        "  ten_percent = row['counts'] // 100 * 1\n",
        "  tmp = df[(df['label'] == row['label']) & (df['judged'] == 1)].sample(n = ten_percent)\n",
        "  df.at[tmp.index, 'status'] = 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "I78G2TuRlPN8",
        "outputId": "72215e50-2c80-4f5e-cdc1-814abc97162f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  status  counts\n",
              "0   test     379\n",
              "1  train   57625"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1447fa51-2da7-497d-8bf1-e85e50a2cc9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status</th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train</td>\n",
              "      <td>57625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1447fa51-2da7-497d-8bf1-e85e50a2cc9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1447fa51-2da7-497d-8bf1-e85e50a2cc9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1447fa51-2da7-497d-8bf1-e85e50a2cc9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df.groupby(['status'])['status'].count().reset_index(name='counts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "A54flYZqngh0",
        "outputId": "b059778a-f9ca-4397-fec4-540de7551e8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df2 = df.groupby(['tweet_tkn_len'])['tweet_tkn_len'].count().reset_index(name='counts')\n",
        "\n",
        "plt.style.use('seaborn')\n",
        "plt.figure(figsize = (6, 6))\n",
        "plt.plot(df2['tweet_tkn_len'], df2['counts'], color = 'black', linestyle = 'dashed')\n",
        "  \n",
        "plt.scatter(df2['tweet_tkn_len'], df2['counts'], marker = 'o', s = 25, color = 'red')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSkf89TtlqtS"
      },
      "source": [
        "## pre-fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Taseb33Sovg0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d5900eab-966d-4fba-ffa4-f754911bb633"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def tokenize_and_format(sentences, model):\n",
        "  if model in ['bert-base-multilingual-cased', 'HooshvareLab/bert-base-parsbert-uncased', 'arm-on/BERTweet-FA']:\n",
        "    tokenizer = BertTokenizer.from_pretrained(model, do_lower_case=True)\n",
        "\n",
        "  elif model == 'xlm-roberta-base':\n",
        "    tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sentence in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sentence,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 64,           # Pad & truncate all sentences.\n",
        "                          padding = 'max_length',\n",
        "                          truncation = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "\n",
        "      # Add the encoded sentence to the list.\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "  return input_ids, attention_masks\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQuvdHDJqzRp"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88efVtq2ZzI0"
      },
      "source": [
        "### get_validation_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O_Mzr-kd5RaY",
        "outputId": "f691ac45-f70d-4362-a3a3-39b7e78e45b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# function to get validation accuracy\n",
        "def get_validation_performance(val_set, model, batch_size, ret_output = False):\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "\n",
        "    num_batches = int(len(val_set)/batch_size) + 1\n",
        "\n",
        "    total_correct = 0\n",
        "    pred_labels = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "\n",
        "        \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "        labels_flat = label_ids.flatten()\n",
        "        pred_labels.extend(list(pred_flat))\n",
        "        num_correct = np.sum(pred_flat == labels_flat)\n",
        "        total_correct += num_correct\n",
        "        \n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_correct / len(val_set)\n",
        "\n",
        "    if ret_output:\n",
        "      return avg_val_accuracy, pred_labels\n",
        "      \n",
        "    return avg_val_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbBzku8mZ2qc"
      },
      "source": [
        "### model_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DKjxCQxdE7Qj",
        "outputId": "8efdb04c-4f9d-4243-fe62-c2f1cc2c9165"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def model_training(model,optimizer, train_set,val_set,_val, batch_size, ju = 'all'):\n",
        "  epochs = 10\n",
        "  ju = 'Unjudged' if ju==0 else 'Judged' if ju==1 else ju\n",
        "  for epoch_i in range(0, epochs):\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} - {:} ========'.format(epoch_i + 1, epochs, ju))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    num_batches = int(len(train_set)/batch_size) + 1\n",
        "\n",
        "    for i in range(num_batches):\n",
        "      end_index = min(batch_size * (i+1), len(train_set))\n",
        "\n",
        "      batch = train_set[i*batch_size:end_index]\n",
        "\n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      label_tensors = torch.stack([data[2] for data in batch])\n",
        "\n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "      b_labels = label_tensors.to(device)\n",
        "\n",
        "      # Clear the previously calculated gradient\n",
        "      model.zero_grad()        \n",
        "\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask, \n",
        "                            labels=b_labels)\n",
        "      loss = outputs.loss\n",
        "      logits = outputs.logits\n",
        "\n",
        "      total_train_loss += loss.item()\n",
        "\n",
        "      # Perform a backward pass to calculate the gradients.\n",
        "      loss.backward()\n",
        "\n",
        "      # Update parameters and take a step using the computed gradient.\n",
        "      optimizer.step()\n",
        "\n",
        "      # ========================================\n",
        "      #               Validation\n",
        "      # ========================================\n",
        "      # After the completion of each training epoch, measure our performance on\n",
        "      # our validation set. Implement this function in the cell above.\n",
        "    print(f\"Total loss: {total_train_loss}\")\n",
        "    val_acc, pred_labels = get_validation_performance(val_set, model, batch_size, ret_output=True)\n",
        "    print(f\"Validation accuracy: {val_acc}\\n\")\n",
        "    print(classification_report(_val['label'], pred_labels, digits=4, zero_division=1, labels=[0,1,2]))\n",
        "  \n",
        "  return model, optimizer, total_train_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIgExFvvZ6Tx"
      },
      "source": [
        "### main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YGhkeLQlNNr8",
        "outputId": "577a2bda-deee-4660-e6d1-bbd4329d236b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def main(_df):\n",
        "  list_model = ['HooshvareLab/bert-base-parsbert-uncased']\n",
        "  # list_model = ['bert-base-multilingual-cased', 'arm-on/BERTweet-FA', 'xlm-roberta-base','HooshvareLab/bert-base-parsbert-uncased']\n",
        "  # list_model = ['arm-on/BERTweet-FA', 'xlm-roberta-base','HooshvareLab/bert-base-parsbert-uncased']\n",
        "\n",
        "  # _df['label'] = _df['label'].apply(lambda x: 0 if x == '0- NO' else 1 if x == '1- Offensive' else 2)\n",
        "  \n",
        "  for _MODEL in list_model:\n",
        "\n",
        "    \n",
        "    batch_size = 64\n",
        "\n",
        "    if _MODEL in ['bert-base-multilingual-cased', 'HooshvareLab/bert-base-parsbert-uncased', 'arm-on/BERTweet-FA']:\n",
        "      model = BertForSequenceClassification.from_pretrained(\n",
        "        _MODEL, # Use the 12-layer BERT model, with an uncased vocab. bert-base-uncased arm-on/BERTweet-FA\n",
        "        # f'arm-on/BERTweet-FA', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "        num_labels = 3, # The number of output labels.   \n",
        "        output_attentions = False, # Whether the model returns attentions weights.\n",
        "        output_hidden_states = False, # Whether the model returns all hidden-states.,        \n",
        "    )\n",
        "      \n",
        "    elif _MODEL == 'xlm-roberta-base':\n",
        "      model = RobertaForSequenceClassification.from_pretrained(\n",
        "        _MODEL,\n",
        "        num_labels = 3, # The number of output labels.   \n",
        "        output_attentions = False, # Whether the model returns attentions weights.\n",
        "        output_hidden_states = False, # Whether the model returns all hidden-states.,\n",
        "    )\n",
        "\n",
        "    # Tell pytorch to run this model on the GPU.\n",
        "    model.cuda()\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                      lr = 2.5e-5, # args.learning_rate - default is 5e-5\n",
        "                      # eps = 1e-15  # args.adam_epsilon  - default is 1e-8\n",
        "                    )\n",
        "    \n",
        "    # for ju in [0, 1]:\n",
        "    # for ju in [1]:\n",
        "    # df = _df.loc[_df['judged'] == ju]\n",
        "    df = _df\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    texts = df.tweet.values\n",
        "    labels = df.label.values\n",
        "\n",
        "    ### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "    input_ids, attention_masks = tokenize_and_format(texts, _MODEL)\n",
        "\n",
        "    # Convert the lists into tensors.\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "\n",
        "    # print('Token IDs:', input_ids[0])\n",
        "\n",
        "\n",
        "    total = len(df.loc[df['status'] == 'train'])\n",
        "\n",
        "    num_train = int(total * .9)\n",
        "    num_val = int(total * .1)\n",
        "    # num_test = total - num_train - num_val\n",
        "    num_test = len(df.loc[df['status'] == 'test'])\n",
        "\n",
        "    _val = df.loc[(df['status'] == 'train')].sample(n = num_val)\n",
        "    # _val = df.loc[(df['status'] == 'train') & (df['judged'] == 1)].sample(n = num_val)\n",
        "    _test = df.loc[df['status'] == 'test']\n",
        "    _train = df.drop(_val.index)\n",
        "    _train = _train.drop(_test.index)\n",
        "\n",
        "    # # make lists of 3-tuples (already shuffled the dataframe in cell above)\n",
        "\n",
        "    train_set = [(input_ids[i], attention_masks[i], labels[i]) for i, row in _train.iterrows()]\n",
        "    val_set = [(input_ids[i], attention_masks[i], labels[i]) for i, row in _val.iterrows()]\n",
        "    test_set = [(input_ids[i], attention_masks[i], labels[i]) for i, row in _test.iterrows()]\n",
        "\n",
        "    train_text = [texts[i] for i, row in _train.iterrows()]\n",
        "    val_text = [texts[i] for i, row in _val.iterrows()]\n",
        "    test_text = [texts[i] for i, row in _test.iterrows()]\n",
        "\n",
        "    # print('train_set', len(train_set))\n",
        "    # print('val_set',len(val_set))\n",
        "    # print('test_set',len(test_set))\n",
        "    # print('train_text',len(train_text))\n",
        "    # print('val_text',len(val_text))\n",
        "    # print('test_text',len(test_text))\n",
        "\n",
        "    model,optimizer,total_train_loss = model_training(model, optimizer, train_set,val_set,_val, batch_size)\n",
        "             \n",
        "\n",
        "        \n",
        "\n",
        "    val_acc, pred_labels = get_validation_performance(test_set, model, batch_size,ret_output=True)\n",
        "\n",
        "    print(\"Test Set Report:\\n\")\n",
        "    print(classification_report(_test['label'], pred_labels, digits=4, labels=[0,1,2]))\n",
        "    print(f\"Test Set accuracy: {val_acc}\\n\")\n",
        "\n",
        "    cm = confusion_matrix(_test['label'], pred_labels)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "    _test['pred'] = pred_labels\n",
        "    df_test = _test[_test['label'] != _test['pred']].sample(n = 10)\n",
        "    for i, row in df_test.iterrows():\n",
        "      print(row['tweet'])\n",
        "      print('Label: ',row['label'],'   Predict: ',row['pred'])\n",
        "      print('====================================================')\n",
        "    \n",
        "    return model\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete! \\n\")\n",
        "  print('====================================================\\n')\n",
        "  print('====================================================\\n\\n\\n\\n\\n')\n",
        "\n",
        "  del optimizer\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ISVNAY2X3zb"
      },
      "source": [
        "## Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt0No7bUs9uX"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "model = main(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X72mumhI9WdR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "37b1363d-29f6-493a-9e50-1767f1ef4c04"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.save_pretrained('/content/modelparsbert/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bias Measurement"
      ],
      "metadata": {
        "id": "Z8aBCXp9c4e_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tokenize_and_format"
      ],
      "metadata": {
        "id": "HWWZcrYLhFFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_format(sentences, model_dir):\n",
        "  \n",
        "  if model_dir == '//content//drive//MyDrive//Colab Notebooks//modelfarsi':\n",
        "    tokenizer = BertTokenizer.from_pretrained('arm-on/BERTweet-FA', do_lower_case=True)\n",
        "\n",
        "  if model_dir == '//content//drive//MyDrive//Colab Notebooks//modelparsbert':\n",
        "    tokenizer = BertTokenizer.from_pretrained('HooshvareLab/bert-base-parsbert-uncased', do_lower_case=True)\n",
        "\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "\n",
        "  # For every sentence...\n",
        "  for sentence in sentences:\n",
        "      # `encode_plus` will:\n",
        "      #   (1) Tokenize the sentence.\n",
        "      #   (2) Prepend the `[CLS]` token to the start.\n",
        "      #   (3) Append the `[SEP]` token to the end.\n",
        "      #   (4) Map tokens to their IDs.\n",
        "      #   (5) Pad or truncate the sentence to `max_length`\n",
        "      #   (6) Create attention masks for [PAD] tokens.\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sentence,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = 64,           # Pad & truncate all sentences.\n",
        "                          padding = 'max_length',\n",
        "                          truncation = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "\n",
        "      # Add the encoded sentence to the list.\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "  return input_ids, attention_masks\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9OX4aZMLc8co",
        "outputId": "9b807827-56c1-4b83-81d8-363fa2c07da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dRSXI4jhD2y"
      },
      "source": [
        "### get_validation_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc14c5c-f819-4db8-d3b2-cd6906549e19",
        "id": "UslMNDPShD25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# function to get validation accuracy\n",
        "def get_validation_performance(val_set, model, batch_size):\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "\n",
        "    num_batches = int(len(val_set)/batch_size) + 1\n",
        "\n",
        "    total_correct = 0\n",
        "    pred_labels = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "\n",
        "      end_index = min(batch_size * (i+1), len(val_set))\n",
        "\n",
        "      batch = val_set[i*batch_size:end_index]\n",
        "      \n",
        "      if len(batch) == 0: continue\n",
        "\n",
        "      input_id_tensors = torch.stack([data[0] for data in batch])\n",
        "      input_mask_tensors = torch.stack([data[1] for data in batch])\n",
        "      \n",
        "      # Move tensors to the GPU\n",
        "      b_input_ids = input_id_tensors.to(device)\n",
        "      b_input_mask = input_mask_tensors.to(device)\n",
        "\n",
        "        \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        \n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "\n",
        "        # Calculate the number of correctly labeled examples in batch\n",
        "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
        "\n",
        "        pred_labels.extend(list(pred_flat))\n",
        "\n",
        "\n",
        "      \n",
        "    return pred_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "9BqBumB2ibDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(df, _MODEL):\n",
        "  # list_model = ['//content//drive//MyDrive//Colab Notebooks//modelfarsi','//content//drive//MyDrive//Colab Notebooks//modelparsbert']\n",
        "  # list_model = ['bert-base-multilingual-cased', 'arm-on/BERTweet-FA', 'xlm-roberta-base','HooshvareLab/bert-base-parsbert-uncased']\n",
        "  # list_model = ['arm-on/BERTweet-FA', 'xlm-roberta-base','HooshvareLab/bert-base-parsbert-uncased']\n",
        "\n",
        "  # _df['label'] = _df['label'].apply(lambda x: 0 if x == '0- NO' else 1 if x == '1- Offensive' else 2)\n",
        "  \n",
        "  # for _MODEL in list_model:\n",
        "    \n",
        "  batch_size = 64\n",
        "\n",
        "  model = BertForSequenceClassification.from_pretrained(_MODEL)\n",
        "\n",
        "\n",
        "  # Tell pytorch to run this model on the GPU.\n",
        "  model.cuda()\n",
        "\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "  texts = df.tweet.values\n",
        "\n",
        "  ### tokenize_and_format() is a helper function provided in helpers.py ###\n",
        "  input_ids, attention_masks = tokenize_and_format(texts, _MODEL)\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  # print('Token IDs:', input_ids[0])\n",
        "\n",
        "\n",
        "  total = len(df)\n",
        "  \n",
        "  _test = df\n",
        "\n",
        "  test_set = [(input_ids[i], attention_masks[i]) for i, row in _test.iterrows()]\n",
        "\n",
        "  test_text = [texts[i] for i, row in _test.iterrows()]\n",
        "\n",
        "            \n",
        "\n",
        "      \n",
        "\n",
        "  pred_labels = get_validation_performance(test_set, model, batch_size)\n",
        "\n",
        "  print(\"Test Set Report:\\n\")\n",
        "  # print(classification_report(_test['label'], pred_labels, digits=4, labels=[0,1,2]))\n",
        "\n",
        "\n",
        "  # cm = confusion_matrix(_test['label'], pred_labels)\n",
        "  # disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  # disp.plot()\n",
        "  # plt.show()\n",
        "  print(\"\\n\")\n",
        "  _test['pred'] = pred_labels\n",
        "  # df_test = _test[_test['label'] != _test['pred']].sample(n = 10)\n",
        "  # for i, row in df_test.iterrows():\n",
        "  #   print(row['tweet'])\n",
        "  #   print('Label: ',row['label'],'   Predict: ',row['pred'])\n",
        "  #   print('====================================================')\n",
        "\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  return _test\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "fYRw1YD5ibWb",
        "outputId": "3ad9ddfd-3a30-409e-d0ee-b239ff3747e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('//content//drive//MyDrive//Colab Notebooks//Files//biasmeasurement//arab.xlsx')\n",
        "\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df['tweet'] = df['tweet'].apply(lambda x: str(x))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "24da5OxBlqhO",
        "outputId": "28d61142-3a65-45bb-b1c9-d55a3b3a54bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_model = ['//content//drive//MyDrive//Colab Notebooks//modelfarsi','//content//drive//MyDrive//Colab Notebooks//modelparsbert']\n",
        "columns = ['arab','kord','lor','tork','balooch','zoroastrian','jewish','islam','christan']\n",
        "outcome = {}\n",
        "for c in columns:\n",
        "  df = pd.read_excel(f'//content//drive//MyDrive//Colab Notebooks//Files//biasmeasurement//{c}.xlsx')\n",
        "  for _model in list_model:\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    df['tweet'] = df['tweet'].apply(lambda x: str(x))\n",
        "    res = main(df, _model)\n",
        "    print(_model)\n",
        "    print(res.groupby([c,'pred'])['pred'].count().reset_index(name='counts'))\n",
        "    print(\"\\n =========== \\n\")\n",
        "    outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFtQhdtsmVZV",
        "outputId": "1f58e414-da58-4e01-8a0e-54b60f33574a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   arab  pred  counts\n",
            "0     0     0    4845\n",
            "1     0     1     145\n",
            "2     0     2      10\n",
            "3     1     0    3500\n",
            "4     1     1     585\n",
            "5     1     2     915\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   arab  pred  counts\n",
            "0     0     0    4811\n",
            "1     0     1     187\n",
            "2     0     2       2\n",
            "3     1     0    3521\n",
            "4     1     1     594\n",
            "5     1     2     885\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   kord  pred  counts\n",
            "0     0     0    4844\n",
            "1     0     1     145\n",
            "2     0     2      11\n",
            "3     1     0    4560\n",
            "4     1     1     326\n",
            "5     1     2     114\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   kord  pred  counts\n",
            "0     0     0    4810\n",
            "1     0     1     187\n",
            "2     0     2       3\n",
            "3     1     0    4530\n",
            "4     1     1     400\n",
            "5     1     2      70\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   lor  pred  counts\n",
            "0    0     0    4844\n",
            "1    0     1     145\n",
            "2    0     2      11\n",
            "3    1     0    4395\n",
            "4    1     1     504\n",
            "5    1     2     101\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   lor  pred  counts\n",
            "0    0     0    4810\n",
            "1    0     1     187\n",
            "2    0     2       3\n",
            "3    1     0    4299\n",
            "4    1     1     622\n",
            "5    1     2      79\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   tork  pred  counts\n",
            "0     0     0    4846\n",
            "1     0     1     144\n",
            "2     0     2      10\n",
            "3     1     0    4455\n",
            "4     1     1     418\n",
            "5     1     2     127\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   tork  pred  counts\n",
            "0     0     0    4812\n",
            "1     0     1     185\n",
            "2     0     2       3\n",
            "3     1     0    4323\n",
            "4     1     1     544\n",
            "5     1     2     133\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   balooch  pred  counts\n",
            "0        0     0    4844\n",
            "1        0     1     145\n",
            "2        0     2      11\n",
            "3        1     0    4423\n",
            "4        1     1     469\n",
            "5        1     2     108\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   balooch  pred  counts\n",
            "0        0     0    4810\n",
            "1        0     1     187\n",
            "2        0     2       3\n",
            "3        1     0    4341\n",
            "4        1     1     602\n",
            "5        1     2      57\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   zoroastrian  pred  counts\n",
            "0            0     0    4844\n",
            "1            0     1     145\n",
            "2            0     2      11\n",
            "3            1     0    4562\n",
            "4            1     1     332\n",
            "5            1     2     106\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   zoroastrian  pred  counts\n",
            "0            0     0    4810\n",
            "1            0     1     187\n",
            "2            0     2       3\n",
            "3            1     0    4269\n",
            "4            1     1     625\n",
            "5            1     2     106\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   jewish  pred  counts\n",
            "0       0     0    4844\n",
            "1       0     1     145\n",
            "2       0     2      11\n",
            "3       1     0    4039\n",
            "4       1     1     709\n",
            "5       1     2     252\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   jewish  pred  counts\n",
            "0       0     0    4810\n",
            "1       0     1     187\n",
            "2       0     2       3\n",
            "3       1     0    3898\n",
            "4       1     1     830\n",
            "5       1     2     272\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   islam  pred  counts\n",
            "0      0     0    4846\n",
            "1      0     1     144\n",
            "2      0     2      10\n",
            "3      1     0    4490\n",
            "4      1     1     303\n",
            "5      1     2     207\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   islam  pred  counts\n",
            "0      0     0    4813\n",
            "1      0     1     185\n",
            "2      0     2       2\n",
            "3      1     0    4417\n",
            "4      1     1     393\n",
            "5      1     2     190\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelfarsi\n",
            "   christan  pred  counts\n",
            "0         0     0    4844\n",
            "1         0     1     145\n",
            "2         0     2      11\n",
            "3         1     0    4406\n",
            "4         1     1     513\n",
            "5         1     2      81\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Report:\n",
            "\n",
            "\n",
            "\n",
            "//content//drive//MyDrive//Colab Notebooks//modelparsbert\n",
            "   christan  pred  counts\n",
            "0         0     0    4810\n",
            "1         0     1     187\n",
            "2         0     2       3\n",
            "3         1     0    4202\n",
            "4         1     1     735\n",
            "5         1     2      63\n",
            "\n",
            " =========== \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-8aac8e64c904>:13: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  outcome[c] = res.groupby([c,'pred'])['pred'].count().reset_index(name='counts').to_dict('record')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in outcome:\n",
        "  count = 0\n",
        "  for j in outcome[i]: \n",
        "    count += j['counts']\n",
        "  print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "IvKCoAvsm6c3",
        "outputId": "1002b4a7-d5d4-4eb9-8c5d-97f6c983d9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'arab': [{'arab': 0, 'pred': 0, 'counts': 4811},\n",
              "  {'arab': 0, 'pred': 1, 'counts': 187},\n",
              "  {'arab': 0, 'pred': 2, 'counts': 2},\n",
              "  {'arab': 1, 'pred': 0, 'counts': 3521},\n",
              "  {'arab': 1, 'pred': 1, 'counts': 594},\n",
              "  {'arab': 1, 'pred': 2, 'counts': 885}],\n",
              " 'kord': [{'kord': 0, 'pred': 0, 'counts': 4810},\n",
              "  {'kord': 0, 'pred': 1, 'counts': 187},\n",
              "  {'kord': 0, 'pred': 2, 'counts': 3},\n",
              "  {'kord': 1, 'pred': 0, 'counts': 4530},\n",
              "  {'kord': 1, 'pred': 1, 'counts': 400},\n",
              "  {'kord': 1, 'pred': 2, 'counts': 70}],\n",
              " 'lor': [{'lor': 0, 'pred': 0, 'counts': 4810},\n",
              "  {'lor': 0, 'pred': 1, 'counts': 187},\n",
              "  {'lor': 0, 'pred': 2, 'counts': 3},\n",
              "  {'lor': 1, 'pred': 0, 'counts': 4299},\n",
              "  {'lor': 1, 'pred': 1, 'counts': 622},\n",
              "  {'lor': 1, 'pred': 2, 'counts': 79}],\n",
              " 'tork': [{'tork': 0, 'pred': 0, 'counts': 4812},\n",
              "  {'tork': 0, 'pred': 1, 'counts': 185},\n",
              "  {'tork': 0, 'pred': 2, 'counts': 3},\n",
              "  {'tork': 1, 'pred': 0, 'counts': 4323},\n",
              "  {'tork': 1, 'pred': 1, 'counts': 544},\n",
              "  {'tork': 1, 'pred': 2, 'counts': 133}],\n",
              " 'balooch': [{'balooch': 0, 'pred': 0, 'counts': 4810},\n",
              "  {'balooch': 0, 'pred': 1, 'counts': 187},\n",
              "  {'balooch': 0, 'pred': 2, 'counts': 3},\n",
              "  {'balooch': 1, 'pred': 0, 'counts': 4341},\n",
              "  {'balooch': 1, 'pred': 1, 'counts': 602},\n",
              "  {'balooch': 1, 'pred': 2, 'counts': 57}],\n",
              " 'zoroastrian': [{'zoroastrian': 0, 'pred': 0, 'counts': 4810},\n",
              "  {'zoroastrian': 0, 'pred': 1, 'counts': 187},\n",
              "  {'zoroastrian': 0, 'pred': 2, 'counts': 3},\n",
              "  {'zoroastrian': 1, 'pred': 0, 'counts': 4269},\n",
              "  {'zoroastrian': 1, 'pred': 1, 'counts': 625},\n",
              "  {'zoroastrian': 1, 'pred': 2, 'counts': 106}],\n",
              " 'jewish': [{'jewish': 0, 'pred': 0, 'counts': 4810},\n",
              "  {'jewish': 0, 'pred': 1, 'counts': 187},\n",
              "  {'jewish': 0, 'pred': 2, 'counts': 3},\n",
              "  {'jewish': 1, 'pred': 0, 'counts': 3898},\n",
              "  {'jewish': 1, 'pred': 1, 'counts': 830},\n",
              "  {'jewish': 1, 'pred': 2, 'counts': 272}],\n",
              " 'islam': [{'islam': 0, 'pred': 0, 'counts': 4813},\n",
              "  {'islam': 0, 'pred': 1, 'counts': 185},\n",
              "  {'islam': 0, 'pred': 2, 'counts': 2},\n",
              "  {'islam': 1, 'pred': 0, 'counts': 4417},\n",
              "  {'islam': 1, 'pred': 1, 'counts': 393},\n",
              "  {'islam': 1, 'pred': 2, 'counts': 190}],\n",
              " 'christan': [{'christan': 0, 'pred': 0, 'counts': 4810},\n",
              "  {'christan': 0, 'pred': 1, 'counts': 187},\n",
              "  {'christan': 0, 'pred': 2, 'counts': 3},\n",
              "  {'christan': 1, 'pred': 0, 'counts': 4202},\n",
              "  {'christan': 1, 'pred': 1, 'counts': 735},\n",
              "  {'christan': 1, 'pred': 2, 'counts': 63}]}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = {'arab': [\n",
        "  {'arab': 0, 'pred': 1, 'counts': 145},\n",
        "  {'arab': 0, 'pred': 2, 'counts': 10},\n",
        "  {'arab': 1, 'pred': 1, 'counts': 585},\n",
        "  {'arab': 1, 'pred': 2, 'counts': 915}],\n",
        " 'kord': [{'kord': 0, 'pred': 1, 'counts': 145},\n",
        "  {'kord': 0, 'pred': 2, 'counts': 11},\n",
        "  {'kord': 1, 'pred': 1, 'counts': 326},\n",
        "  {'kord': 1, 'pred': 2, 'counts': 114}],\n",
        " 'lor': [ {'lor': 0, 'pred': 1, 'counts': 145},\n",
        "  {'lor': 0, 'pred': 2, 'counts': 11},\n",
        "  {'lor': 1, 'pred': 1, 'counts': 504},\n",
        "  {'lor': 1, 'pred': 2, 'counts': 101}],\n",
        " 'tork': [ {'tork': 0, 'pred': 1, 'counts': 144},\n",
        "  {'tork': 0, 'pred': 2, 'counts': 10},\n",
        "  {'tork': 1, 'pred': 1, 'counts': 418},\n",
        "  {'tork': 1, 'pred': 2, 'counts': 127}],\n",
        " 'balooch': [ {'balooch': 0, 'pred': 1, 'counts': 145},\n",
        "  {'balooch': 0, 'pred': 2, 'counts': 11},\n",
        "  {'balooch': 1, 'pred': 1, 'counts': 469},\n",
        "  {'balooch': 1, 'pred': 2, 'counts': 108}],\n",
        " 'zoroastrian': [{'zoroastrian': 0, 'pred': 1, 'counts': 145},\n",
        "  {'zoroastrian': 0, 'pred': 2, 'counts': 11},\n",
        "  {'zoroastrian': 1, 'pred': 1, 'counts': 332},\n",
        "  {'zoroastrian': 1, 'pred': 2, 'counts': 106}],\n",
        " 'jewish': [{'jewish': 0, 'pred': 1, 'counts': 145},\n",
        "  {'jewish': 0, 'pred': 2, 'counts': 11},\n",
        "  {'jewish': 1, 'pred': 1, 'counts': 709},\n",
        "  {'jewish': 1, 'pred': 2, 'counts': 252}],\n",
        " 'islam': [ {'islam': 0, 'pred': 1, 'counts': 144},\n",
        "  {'islam': 0, 'pred': 2, 'counts': 10},\n",
        "  {'islam': 1, 'pred': 1, 'counts': 303},\n",
        "  {'islam': 1, 'pred': 2, 'counts': 207}],\n",
        " 'christan': [  {'christan': 0, 'pred': 1, 'counts': 145},\n",
        "  {'christan': 0, 'pred': 2, 'counts': 11},\n",
        "  {'christan': 1, 'pred': 1, 'counts': 513},\n",
        "  {'christan': 1, 'pred': 2, 'counts': 81}]}"
      ],
      "metadata": {
        "id": "C2lXZIzUnx33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(columns=['sub', 'class', 'true', 'false'])\n",
        "for i in res:\n",
        "  _p0 = res[i][0]['counts'] / 5000\n",
        "  _p2 = res[i][2]['counts'] / 5000\n",
        "  df.at[len(df)] = [i, 1, _p2, _p0]\n",
        "\n",
        "  _p1 = res[i][1]['counts'] / 5000\n",
        "  _p3 = res[i][3]['counts'] / 5000\n",
        "  df.at[len(df)] = [i, 2, _p3, _p1]\n",
        "\n",
        "df['true/false'] = df['true'] / df['false']\n",
        "df#.to_dict('record')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "VQ-n4RL_Hldv",
        "outputId": "b001db4b-e3c6-4c9d-8c29-ab593f77dc15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            sub class    true   false true/false\n",
              "0          arab     1   0.117   0.029   4.034483\n",
              "1          arab     2   0.183   0.002       91.5\n",
              "2          kord     1  0.0652   0.029   2.248276\n",
              "3          kord     2  0.0228  0.0022  10.363636\n",
              "4           lor     1  0.1008   0.029   3.475862\n",
              "5           lor     2  0.0202  0.0022   9.181818\n",
              "6          tork     1  0.0836  0.0288   2.902778\n",
              "7          tork     2  0.0254   0.002       12.7\n",
              "8       balooch     1  0.0938   0.029   3.234483\n",
              "9       balooch     2  0.0216  0.0022   9.818182\n",
              "10  zoroastrian     1  0.0664   0.029   2.289655\n",
              "11  zoroastrian     2  0.0212  0.0022   9.636364\n",
              "12       jewish     1  0.1418   0.029   4.889655\n",
              "13       jewish     2  0.0504  0.0022  22.909091\n",
              "14        islam     1  0.0606  0.0288   2.104167\n",
              "15        islam     2  0.0414   0.002       20.7\n",
              "16     christan     1  0.1026   0.029   3.537931\n",
              "17     christan     2  0.0162  0.0022   7.363636"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a062d31-68b6-4efd-ae2a-d0d8c4f2cfcb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sub</th>\n",
              "      <th>class</th>\n",
              "      <th>true</th>\n",
              "      <th>false</th>\n",
              "      <th>true/false</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arab</td>\n",
              "      <td>1</td>\n",
              "      <td>0.117</td>\n",
              "      <td>0.029</td>\n",
              "      <td>4.034483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>arab</td>\n",
              "      <td>2</td>\n",
              "      <td>0.183</td>\n",
              "      <td>0.002</td>\n",
              "      <td>91.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kord</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0652</td>\n",
              "      <td>0.029</td>\n",
              "      <td>2.248276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kord</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0228</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>10.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lor</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1008</td>\n",
              "      <td>0.029</td>\n",
              "      <td>3.475862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lor</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0202</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>9.181818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tork</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0836</td>\n",
              "      <td>0.0288</td>\n",
              "      <td>2.902778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tork</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0254</td>\n",
              "      <td>0.002</td>\n",
              "      <td>12.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>balooch</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0938</td>\n",
              "      <td>0.029</td>\n",
              "      <td>3.234483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>balooch</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0216</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>9.818182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>zoroastrian</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0664</td>\n",
              "      <td>0.029</td>\n",
              "      <td>2.289655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>zoroastrian</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0212</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>9.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>jewish</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.029</td>\n",
              "      <td>4.889655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>jewish</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0504</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>22.909091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>islam</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.0288</td>\n",
              "      <td>2.104167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>islam</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0414</td>\n",
              "      <td>0.002</td>\n",
              "      <td>20.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>christan</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1026</td>\n",
              "      <td>0.029</td>\n",
              "      <td>3.537931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>christan</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0162</td>\n",
              "      <td>0.0022</td>\n",
              "      <td>7.363636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a062d31-68b6-4efd-ae2a-d0d8c4f2cfcb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a062d31-68b6-4efd-ae2a-d0d8c4f2cfcb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a062d31-68b6-4efd-ae2a-d0d8c4f2cfcb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hInQiAMKwxRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1sC7vclyLA2F",
        "DyuCu2y9lmBM",
        "WSkf89TtlqtS",
        "88efVtq2ZzI0",
        "cbBzku8mZ2qc",
        "lIgExFvvZ6Tx"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}